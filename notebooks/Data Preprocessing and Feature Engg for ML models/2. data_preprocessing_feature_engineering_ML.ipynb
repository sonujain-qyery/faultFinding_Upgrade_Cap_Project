{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d7f0c39-993f-4343-9785-ec8a2569bfa9",
   "metadata": {},
   "source": [
    "Image Data Preprocessing:\n",
    "\n",
    "Resizing: Images may come in various sizes, and resizing them to a uniform size is often necessary for model compatibility and efficiency.\n",
    "\n",
    "Normalization: Normalizing pixel values helps in improving model convergence and performance. Typically, this involves scaling pixel values to a range like [0, 1] or [-1, 1].\n",
    "\n",
    "Color Space Conversion: Converting images to different color spaces (e.g., RGB, grayscale, HSV) can sometimes improve model performance or reduce computational complexity.\n",
    "\n",
    "Handling Missing Data: Sometimes, images may have missing data or be corrupted. Dealing with such cases might involve image inpainting or removing the corrupted images from the dataset.\n",
    "\n",
    "Feature Engineering for Image Data:\n",
    "    \n",
    "Feature Extraction: This involves extracting relevant features from images that are informative for the given task. Features can include edges, textures, shapes, or more abstract representations learned through convolutional neural networks (CNNs).\n",
    "\n",
    "Dimensionality Reduction: High-dimensional image data can be computationally expensive and prone to overfitting. Techniques like Principal Component Analysis (PCA) or t-SNE can be applied to reduce the dimensionality of the feature space while preserving important information.\n",
    "\n",
    "Histogram of Oriented Gradients (HOG): HOG is a feature descriptor technique used for object detection. It calculates the distribution of intensity gradients in localized portions of an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82697519-90a8-4db3-a227-a620f09943f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Library [Details are available in README.md file]\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b0ebf1-3b07-483a-9c42-5a7dad2f4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is defined to convert image data set orientation and pixels\n",
    "def extract_hog_features(image):\n",
    "\t# Calculate HOG features\n",
    "\thog_features = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "\tcells_per_block=(2, 2), visualize=False)\n",
    "\treturn hog_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2f06cd7-546d-429f-be12-5765f5236c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our data data set is in the form of Image so to work with machine learning models , it should in the numeric form.\n",
    "# Also with the help of cv2 module , we will process the data\n",
    "def load_and_extract_features(directory):\n",
    "\tX = []\n",
    "\ty = []\n",
    "\tfor label in os.listdir(directory):\n",
    "\t\tlabel_dir = os.path.join(directory, label)\n",
    "\t\tfor filename in os.listdir(label_dir):\n",
    "\t\t\timage_path = os.path.join(label_dir, filename)\n",
    "\t\t\t# Load image using OpenCV\n",
    "\t\t\timg = cv2.imread(image_path)\n",
    "\t\t\t# Resize image to (128, 128)\n",
    "\t\t\timg_resized = cv2.resize(img, (128, 128))\n",
    "\t\t\t# Convert image to grayscale\n",
    "\t\t\timg_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t# Calculate HOG features\n",
    "\t\t\thog_features = extract_hog_features(img_gray)\n",
    "\t\t\tX.append(hog_features)\n",
    "\t\t\ty.append(label)\n",
    "\treturn X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d466fe87-7abb-454c-9122-6440619d2040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Directory: E:\\upgrade_capston_project-main\n"
     ]
    }
   ],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory (one level up)\n",
    "current_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Get the parent directory (one level up)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Print the parent directory\n",
    "print(\"Parent Directory:\", parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e438dcaa-c692-4a84-848f-11f8e6c91d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and extract features from training data\n",
    "dataset_X, dataset_y = load_and_extract_features(parent_dir+\"/datasets/raw_dataset/Digital images of defective and good condition tyres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd4ddc3-fe10-495c-a108-5038825a00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset for training and validation purpose in the 80-20 ratio\n",
    "X_train,X_test,y_train,y_test = train_test_split(dataset_X,dataset_y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0d509f-9e32-4e77-bba9-fe79e98708c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data which will be helpful to train multiple Machine learning models\n",
    "with open(parent_dir+'/datasets/processed_dataset/X_train.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "\n",
    "with open(parent_dir+'/datasets/processed_dataset/X_test.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test, f)\n",
    "\n",
    "with open(parent_dir+'/datasets/processed_dataset/y_train.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open(parent_dir+'/datasets/processed_dataset/y_test.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97734663-42f4-415a-bbe6-aed1b3e00f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_images(directory, num_images=5):\n",
    "# \tfig, axes = plt.subplots(2, num_images, figsize=(15, 5))\n",
    "# \tfig.suptitle(f\"Images from {directory.split('/')[-1]}\", fontsize=16)\n",
    "\t\n",
    "# \tfor i, label in enumerate(os.listdir(directory)):\n",
    "# \t\tlabel_dir = os.path.join(directory, label)\n",
    "# \t\timage_files = os.listdir(label_dir)\n",
    "# \t\trandom.shuffle(image_files)\n",
    "# \t\tfor j in range(num_images):\n",
    "# \t\t\timage_path = os.path.join(label_dir, image_files[j])\n",
    "# \t\t\timg = cv2.imread(image_path)\n",
    "# \t\t\taxes[i, j].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# \t\t\taxes[i, j].set_title(f\"{label} Image {j+1}\")\n",
    "# \t\t\taxes[i, j].axis('off')\n",
    "# \tplt.tight_layout()\n",
    "# \tplt.show()\n",
    "\n",
    "# # Display training images\n",
    "# display_images(parent_dir+\"/datasets/raw_dataset/Digital images of defective and good condition tyres\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
